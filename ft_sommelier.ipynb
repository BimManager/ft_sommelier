{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.1: Exploring the green reds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Writing a function that will plot a scatterplot matrix of the red wine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def plot_scatter_matrix(wine_data, good_threshold, bad_threshold, save_plot=False):\n",
    "    good_df = wine_data[wine_data['quality'] > good_threshold]\n",
    "    bad_df = wine_data[wine_data['quality'] < bad_threshold]\n",
    "    cols = wine_data.columns;\n",
    "    size = len(cols);\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    gs1 = gridspec.GridSpec(size, size)\n",
    "    gs1.update(wspace=0, hspace=0)\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if (i == j):\n",
    "                ax = fig.add_subplot(gs1[i,j], xticks=[], yticks=[])\n",
    "                ax.text(0.5, 0.5, cols[i], horizontalalignment='center',\n",
    "                        verticalalignment='center')\n",
    "                continue ;\n",
    "            ax = fig.add_subplot(gs1[i,j], xticks=[], yticks=[])\n",
    "            ax.scatter(good_df[cols[i]], good_df[cols[j]], c='#D41159')\n",
    "            ax.scatter(bad_df[cols[i]], bad_df[cols[j]], c='#1A85FF')\n",
    "    if (save_plot):\n",
    "        fig.savefig('scatter_matrix.png')\n",
    "    plt.show()\n",
    "    \n",
    "df = pd.read_csv('./winequality-red.csv', sep=';')\n",
    "good, bad = 7, 4\n",
    "plot_scatter_matrix(df, 7, 4, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Useful factors for my perceptron to distinguish high-quality from low-quality wines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the plot, the most useful features to train my perceptron are pH and alcohol. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.2: Learning to perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) & b) Perceptron implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def prep_train_data(df:'pd.DataFrame', good_threshold:'int',\n",
    "                    bad_threshold:'int', features:'list', randomise:'bool'=True) -> 'pd:DataFrame':\n",
    "    good_df, bad_df = df[df['quality'] > good_threshold], df[df['quality'] < bad_threshold]\n",
    "    good_df, bad_df = good_df[features], bad_df[features]\n",
    "    if (randomise):\n",
    "        train_df = pd.concat([good_df, bad_df], axis = 0).sample(frac=1)\n",
    "    else:\n",
    "        train_df = pd.concat([good_df, bad_df], axis = 0)\n",
    "    train_df['quality'] = train_df['quality'].apply(lambda x: 1 if x > good_threshold else -1)\n",
    "    return (train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "'''\n",
    "    X: feature matrix\n",
    "    xi: ith feature vector (row vector)\n",
    "    y: class labels vector (column vector)\n",
    "'''\n",
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, bias:'float'=1.0, seed:'int'=42):\n",
    "        self.bias = bias\n",
    "        self.seed = seed\n",
    "\n",
    "    def net_input(self, xi:'numpy.ndarray') -> 'float':\n",
    "         return sum([x * w for x, w in zip(xi, self.weights[1:])]) + self.weights[0]\n",
    "    \n",
    "    def activation(self, xi:'numpy.ndarray') -> 'float':\n",
    "        return 1.0 if self.net_input(xi) >= 0.0 else -1.0\n",
    "    \n",
    "    def predict(self, X:'numpy.ndarray') -> 'numpy.ndarray':\n",
    "        return [self.activation(xi) for xi in X]\n",
    "\n",
    "    def init_weights(self, X:'numpy.ndarray') -> None:\n",
    "        random.seed(self.seed)\n",
    "        self.weights = [random.randrange(100)/10000 * (-1)**(i%2) for i in range(len(X[0]) + 1)]\n",
    "        self.weights[0] = self.bias\n",
    "\n",
    "    def update_weights(self, xi, error) -> None:\n",
    "        self.weights[0] += self.eta * error\n",
    "        for k in range(len(self.weights) - 1):\n",
    "            self.weights[k + 1] += self.eta * error * xi[k]\n",
    "    \n",
    "    def train(self, X:'numpy.ndarray', y:'numpy.ndarray', eta:'float', n_epochs:'int') -> 'list':\n",
    "        self.init_weights(X)\n",
    "        self.eta = eta\n",
    "        performance = []\n",
    "        until_fit = True if 0 == n_epochs else False\n",
    "        n_epochs = n_epochs if n_epochs > 0 else sys.maxsize\n",
    "        for i_epoch in range(n_epochs):\n",
    "            n_errors = 0\n",
    "            for i_x in range(len(X)):\n",
    "                activation = self.activation(X[i_x])\n",
    "                error = y[i_x] - activation\n",
    "                n_errors += abs(error)#**2\n",
    "                self.update_weights(X[i_x], error)\n",
    "            performance.append((i_epoch, n_errors, self.weights, self.weights[0]))\n",
    "            if not n_errors and until_fit:\n",
    "                break\n",
    "        return performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Plot the perceptron's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_performance(performance:'tuple', wine_data:'pd.DataFrame', \n",
    "                     good_threshold:'int', bad_threshold:'int',\n",
    "                    epoch:'int'=-1, save_plot:'bool'=False) -> None:\n",
    "    if epoch >= performance[-1][0]: epoch = performance[-1][0]\n",
    "    if epoch < -performance[-1][0] - 1: epoch = -performance[-1][0] - 1\n",
    "    n_errors = [t[1] for t in performance]\n",
    "    n_epochs = [t[0] for t in performance]\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    ax = fig.add_subplot(1,2,1, title='Errors as a function of epoch',\n",
    "                        xlabel='epoch', ylabel='classification error')\n",
    "    ax.plot([t[0] for t in performance], [t[1] for t in performance])\n",
    "    ax = fig.add_subplot(1,2,2, title='Decision boundary on epoch {}'.format(\n",
    "        epoch if epoch >= 0 else len(performance)), xlabel=wine_data.columns[0], ylabel=wine_data.columns[1])\n",
    "    perf_at = performance[epoch];\n",
    "    good_df = wine_data[wine_data['quality'] > good_threshold]\n",
    "    bad_df = wine_data[wine_data['quality'] < bad_threshold]\n",
    "    ax.scatter(good_df.iloc[:,0], good_df.iloc[:,1], c='#D41159', label='good (>%d score)'%good_threshold)\n",
    "    ax.scatter(bad_df.iloc[:,0], bad_df.iloc[:,1], c='#1A85FF', label='bad (<%d score)'%bad_threshold)\n",
    "    w1, w2, b = perf_at[2][1], perf_at[2][2], perf_at[2][0]\n",
    "    y = lambda x: (-(b / w2) / (b / w1))*x + (-b / w2)\n",
    "    offset = 0.1\n",
    "    x_min, x_max = wine_data.iloc[:,0].min() - offset, wine_data.iloc[:,0].max() + offset\n",
    "    y_min, y_max = wine_data.iloc[:,1].min() - offset, wine_data.iloc[:,1].max() + offset\n",
    "    ax.plot([x_min,x_max], [y(x_min), y(x_max)], label='decision boundary', linestyle='--')\n",
    "    ax.fill_between([x_min,x_max], [y(x_min), y(x_max)], y_min, alpha=0.1, color='#D41159')\n",
    "    ax.fill_between([x_min,x_max], [y(x_min), y(x_max)], y_max, alpha=0.1, color='#1A85FF')\n",
    "    plt.axis([x_min, x_max, y_min, y_max])\n",
    "    plt.legend()\n",
    "    \n",
    "df = pd.read_csv('./winequality-red.csv', sep = ';')\n",
    "train_df = prep_train_data(df, 7, 4, ['alcohol', 'pH', 'quality'], randomise=True)\n",
    "X = train_df.iloc[:,:-1].values\n",
    "y = train_df.iloc[:,-1].values\n",
    "perceptron = Perceptron()\n",
    "performance = perceptron.train(X, y, 0.5, 0)\n",
    "train_df['quality'] = df['quality']\n",
    "plot_performance(performance, train_df, 7, 4)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Feature scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./winequality-red.csv', sep = ';')\n",
    "train_df = prep_train_data(df, 7, 4, ['alcohol', 'pH', 'quality'])\n",
    "perceptron = Perceptron()\n",
    "\n",
    "#   raw data\n",
    "X = train_df.iloc[:,:-1].values\n",
    "y = train_df.iloc[:,-1].values\n",
    "performance = perceptron.train(X, y, 0.5, 0)\n",
    "train_df['quality'] = df['quality']\n",
    "plot_performance(performance, train_df, 7, 4)\n",
    "    \n",
    "#    data normalisation\n",
    "norm_df = (train_df - train_df.mean()) / (train_df.max() - train_df.min())\n",
    "norm_df['quality'] = df['quality'].apply(lambda x: 1 if x > 7 else -1)\n",
    "X = norm_df.iloc[:,:-1].values\n",
    "y = norm_df.iloc[:,-1].values\n",
    "performance = perceptron.train(X, y, 0.1, 0)\n",
    "norm_df['quality'] = df['quality']\n",
    "plot_performance(performance, norm_df, 7, 4, -1)\n",
    "    \n",
    "#   data standardisation\n",
    "std_df = (train_df - train_df.min()) / train_df.std()\n",
    "std_df['quality'] = df['quality'].apply(lambda x: 1 if x > 7 else -1)\n",
    "X = std_df.iloc[:,:-1].values\n",
    "y = std_df.iloc[:,-1].values\n",
    "performance = perceptron.train(X, y, 0.1, 0)\n",
    "std_df['quality'] = df['quality']\n",
    "plot_performance(performance, std_df, 7, 4, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.3: My fair ADALINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Wines with scores less than 7 and greater than 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = prep_train_data(df, 6, 5, ['alcohol', 'pH', 'quality'])\n",
    "X = train_df.iloc[:,:-1].values\n",
    "y = train_df.iloc[:,-1].values\n",
    "performance = perceptron.train(X, y, 0.1, 12000)\n",
    "train_df['quality'] = df['quality']\n",
    "plot_performance(performance, train_df, 6, 5, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) & c) Gradient descent and ADALINE implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Adaline(object):\n",
    "    def __init__(self, bias:'float'=1.0, seed:'int'=42):\n",
    "        self.bias = bias\n",
    "        self.seed = seed\n",
    "        \n",
    "    def net_input(self, X:'numpy.ndarray') -> 'list':\n",
    "        net_input = []\n",
    "        for xi in X:\n",
    "            net_input.append(sum([x*w for x,w in zip(xi, self.weights[1:])]) + self.weights[0])\n",
    "        return net_input\n",
    "    \n",
    "    def activation(self, X:'numpy.ndarray') -> 'list':\n",
    "        return self.net_input(X)\n",
    "    \n",
    "    def activation2(self, X:'numpy.ndarray') -> 'list':\n",
    "        Z = self.net_input(X)\n",
    "        return [1 / (1 + math.exp(-z)) for z in Z]\n",
    "\n",
    "    def predict(self, X:'numpy.ndarray') -> 'list':\n",
    "        return [1 if xi >= 0.0 else -1 for xi in self.activation(X)]\n",
    "\n",
    "    def predict2(self, X:'numpy.ndarray') -> 'list':\n",
    "        return [1 if xi >= .5 else -1 for xi in self.activation(X)]\n",
    "    \n",
    "    def init_weights(self, X:'numpy.ndarray') -> None:\n",
    "        random.seed(self.seed)\n",
    "        self.weights = [random.randint(1,100) / 10000 * (-1) ** (i % 2)\n",
    "                        for i in range(len(X[0]) + 1)]\n",
    "        self.weights[0] = self.bias\n",
    "       \n",
    "    def update_weights(self, X:'numpy.ndarray', errors:'list') -> None:\n",
    "        self.weights[0] += self.eta * sum(errors)\n",
    "        for wi in range(len(self.weights[1:])):\n",
    "                for xi in range(len(X)):\n",
    "                    self.weights[wi + 1] += self.eta * errors[xi] * X[xi][wi]\n",
    "        \n",
    "    def train(self, X:'np.ndarray', y:'np.ndarray', eta:'float',\n",
    "              n_epochs:'int', batch:'bool'=True) -> 'list':\n",
    "        self.eta = eta\n",
    "        self.init_weights(X)\n",
    "        until_fit = True if 0 == n_epochs else False\n",
    "        n_epochs = n_epochs if n_epochs > 0 else sys.maxsize\n",
    "        performance = []\n",
    "        for i_epoch in range(n_epochs):\n",
    "            if (batch):\n",
    "                output = self.activation(X)\n",
    "                errors = (y - output)\n",
    "                self.update_weights(X, errors)\n",
    "                cost = sum([x**2 for x in errors]) / 2.0\n",
    "            else:\n",
    "                errors = []\n",
    "                for xi, target in zip(X, y):\n",
    "                    output = self.net_input([xi])\n",
    "                    error = target - output\n",
    "                    errors.append(error[0])\n",
    "                    self.update_weights([xi], error)\n",
    "                cost = sum(((y - self.activation(X))**2)) / 2.0\n",
    "            performance.append((i_epoch, cost, self.weights, self.weights[0]))\n",
    "            if (0 == sum(y - self.predict(X)) and until_fit):\n",
    "                break\n",
    "        return performance                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Find a good learning rate for ADALINE and plot the number of classifications errors vs epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./winequality-red.csv', sep = ';')\n",
    "train_df = prep_train_data(df, 7, 4, ['alcohol', 'pH', 'quality'], randomise=True)\n",
    "adaline = Adaline(seed=55)\n",
    "X = train_df.iloc[:,:-1].copy().values\n",
    "y = train_df.iloc[:,-1].copy().values\n",
    "train_df['quality'] = df['quality']\n",
    "performance = adaline.train(X, y, 0.01, 10)\n",
    "plot_performance(performance, train_df, 7, 4)\n",
    "performance = adaline.train(X, y, 0.0005, 0) \n",
    "plot_performance(performance, train_df, 7, 4)\n",
    "performance = adaline.train(X, y, 0.0001, 0)\n",
    "plot_performance(performance, train_df, 7, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.4 Advanced wine sampling and resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Partitioning data into a training and validation set using the holdout method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout(df:'pd.DataFrame', k:'int') -> 'tuple':\n",
    "    k = k if k <= 1 and k > 0 else 1\n",
    "    n_rows = len(df.iloc[:])\n",
    "    k = int(n_rows * k)\n",
    "    train_df = df.iloc[:k]\n",
    "    validation_df = df.iloc[k:]\n",
    "    return (train_df, validation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Generate a k-fold cross validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    k - the number of groups the given data is split into\n",
    "    \n",
    "    1. shuffle the data randomly\n",
    "    2. split the data into k groups of approximately equal size\n",
    "    the first fold is a validation set and the rest are training sets\n",
    "'''\n",
    "def k_fold(df:'pd.DataFrame', k:'int'=10, shuffle:'bool' = True) -> 'tuple':\n",
    "    folds = []\n",
    "    if (shuffle):\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "    n_per_fold = int(len(df.iloc[:]) / k)\n",
    "    for i in range(k):\n",
    "        folds.append(df.iloc[int(i*n_per_fold):int(n_per_fold)*(i+1)])\n",
    "    kfolds = []\n",
    "    for i in range(k):\n",
    "        cp = folds[:]\n",
    "        valid_df = cp.pop(i)\n",
    "        train_df = pd.concat(cp)\n",
    "        kfolds.append((train_df, valid_df))\n",
    "    return kfolds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Evaluating Adaline via k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_validation(model, df:'pd.DataFrame', k:'int'=10,\n",
    "                      n_epochs:'int'=0, eta:'int'=0.001) -> None:\n",
    "    kfolds = k_fold(df, k)\n",
    "    errors = []\n",
    "    accuracy = 0\n",
    "    for i in range(k):\n",
    "        X = kfolds[i][0].iloc[:,:-1].values\n",
    "        y = kfolds[i][0].iloc[:,-1].values\n",
    "        model.train(X, y, eta, n_epochs)\n",
    "        X = kfolds[i][1].iloc[:,:-1].values\n",
    "        y = kfolds[i][1].iloc[:,-1].values\n",
    "        predictions = model.predict(X)\n",
    "        for target, pred in zip(y, predictions):\n",
    "            accuracy += int(target == pred)\n",
    "    print('{}'.format(list(df.columns)), end=' ')\n",
    "    print('k: %d epochs: %d eta: %f accuracy: %f' %\n",
    "          (k, n_epochs, eta, accuracy / (k * len(y))))\n",
    "\n",
    "df = pd.read_csv('./winequality-red.csv', sep=';')\n",
    "df = prep_train_data(df, 7, 4, ['alcohol','pH','quality'], randomise=False)\n",
    "ada = Adaline()\n",
    "k_fold_validation(ada, df, 10, eta=0.0001)\n",
    "k_fold_validation(ada, df, 10, 500, eta=0.0001)\n",
    "k_fold_validation(ada, df, 10, 1000, eta=0.0001)\n",
    "k_fold_validation(ada, df, 10, eta=0.0005)\n",
    "k_fold_validation(ada, df, 10, 500, eta=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.5 Adventures in the Nth dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Train Adaline and Perceptron with different numbers and types of chemicals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('./winequality-red.csv', sep=';')\n",
    "perceptron = Perceptron()\n",
    "adaline = Adaline()\n",
    "columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'quality']\n",
    "train_df = prep_train_data(df, 7, 4, columns)\n",
    "k_fold_validation(adaline, train_df, eta=0.0005, n_epochs=1000)\n",
    "k_fold_validation(perceptron, train_df, eta=0.01, n_epochs=1000)\n",
    "\n",
    "columns = ['residual sugar', 'density', 'sulphates', 'quality']\n",
    "train_df = prep_train_data(df, 7, 4, columns)\n",
    "k_fold_validation(adaline, train_df, eta=0.0005, n_epochs=1000)\n",
    "k_fold_validation(perceptron, train_df, eta=0.01, n_epochs=1000)\n",
    "\n",
    "columns = ['alcohol', 'pH', 'sulphates', 'quality']\n",
    "train_df = prep_train_data(df, 7, 4, columns)\n",
    "k_fold_validation(adaline, train_df, eta=0.0005, n_epochs=1000)\n",
    "k_fold_validation(perceptron, train_df, eta=0.01, n_epochs=1000)\n",
    "\n",
    "columns = list(df.columns)\n",
    "train_df = prep_train_data(df, 7, 4, columns)\n",
    "k_fold_validation(adaline, train_df, eta=0.00001, n_epochs=500)\n",
    "k_fold_validation(perceptron, train_df, eta=0.01, n_epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) What does the decision boundary for N factors look like? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the decision boundary for N-feature data is (N-1)-dimensional hyperplane, for three-feature data it will be a plane. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.6 Marvin's rebuttal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Classify the Pan-Galactic Gargle Blaster dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Pan Galactic Gargle Blaster.csv', sep=';')\n",
    "good = 5\n",
    "bad = 6\n",
    "plot_scatter_matrix(df, good, bad)\n",
    "train_df = prep_train_data(df, good, bad, list(df.columns))\n",
    "norm_df = (train_df - train_df.mean()) / (train_df.max() - train_df.min())\n",
    "x1 = norm_df.iloc[:,0]\n",
    "x2 = norm_df.iloc[:,1]\n",
    "norm_df = norm_df.assign(r=pd.Series(x1*x1 + x2*x2).pow(1./2))\n",
    "norm_df = norm_df.assign(phi=pd.Series([math.atan2(x, y) for x, y in zip(x1,x2)]))\n",
    "norm_df = norm_df[['phi', 'r', 'quality']]\n",
    "norm_df['quality'] = df['quality']\n",
    "plot_scatter_matrix(norm_df, good, bad)\n",
    "norm_df['quality'] = norm_df['quality'].apply(lambda x: 1 if x > good else -1)\n",
    "X = norm_df.iloc[:,:-1].copy().values\n",
    "y = norm_df.iloc[:,-1].copy().values\n",
    "norm_df['quality'] = df['quality']\n",
    "ada = Adaline()\n",
    "performance = ada.train(X, y, 0.0001, 0)\n",
    "plot_performance(performance, norm_df, good, bad)\n",
    "perceptron = Perceptron()\n",
    "performance = perceptron.train(X, y, 0.001, 0)\n",
    "plot_performance(performance, norm_df, good, bad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
